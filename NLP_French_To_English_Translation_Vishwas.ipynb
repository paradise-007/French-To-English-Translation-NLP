{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paradise-007/French-To-English-Translation-NLP/blob/main/NLP_French_To_English_Translation_Vishwas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PRACTICAL 9 - NLP**"
      ],
      "metadata": {
        "id": "bxZoLPd2WDlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.analyticsvidhya.com/blog/2020/08/a-simple-introduction-to-sequence-to-sequence-models/"
      ],
      "metadata": {
        "id": "qEuRALvdbRf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/nlp-sequence-to-sequence-networks-part-2-seq2seq-model-encoderdecoder-model-6c22e29fd7e1"
      ],
      "metadata": {
        "id": "Eb8-fIswbu0j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejRbOhibEf35",
        "outputId": "2a7fbb5b-d756-4e4b-f01f-42807db98e89"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pun7VarqeGL4"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import io\n",
        "import numpy as np\n",
        "from unicodedata import normalize\n",
        "import keras, tensorflow\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loWhpFWfCo1N"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C92VgDWZeGMA"
      },
      "source": [
        "def read_data(file):\n",
        "    data = []\n",
        "    with io.open(file, 'r') as file:\n",
        "        for entry in file:\n",
        "            entry = entry.strip()\n",
        "            data.append(entry)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wccatfy6eGMX"
      },
      "source": [
        "data = read_data('/content/drive/MyDrive/2021_Courses/NLP/Practicals/Practical10/bilingual_pairs.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bv0OgluCo1U"
      },
      "source": [
        "## Some basics about our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzHoS8VxCo1V",
        "outputId": "8f2d0c50-d348-4104-92de-9fc24103fc4a"
      },
      "source": [
        "data[139990:140000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Never choose a vocation just because the hours are short.\\tNe choisissez jamais une profession juste parce que les heures y sont courtes.',\n",
              " \"No other mountain in the world is so high as Mt. Everest.\\tAucune montagne au monde n'atteint la hauteur du Mont Everest.\",\n",
              " \"No sooner had he met his family than he burst into tears.\\tÀ peine avait-il rencontré sa famille qu'il éclata en sanglots.\",\n",
              " \"Nothing is more disappointing than to lose in the finals.\\tRien n'est plus décevant que de perdre en finale.\",\n",
              " \"Now that he is old, it is your duty to go look after him.\\tÀ présent qu'il est vieux, c'est ton devoir de veiller sur lui.\",\n",
              " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que vous avez décidé de quitter votre emploi, vous avez l'air heureux.\",\n",
              " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que tu as décidé de quitter ton emploi, tu as l'air heureux.\",\n",
              " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que vous avez décidé de quitter votre emploi, vous avez l'air heureuse.\",\n",
              " \"Now that you've decided to quit your job, you look happy.\\tMaintenant que tu as décidé de quitter ton emploi, tu as l'air heureuse.\",\n",
              " 'Please drop in when you happen to be in the neighborhood.\\tVeuillez donc passer quand vous êtes dans le coin !']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7v6YuIQqkdC",
        "outputId": "16dd4582-286b-4e92-a54e-3caa0bbd3bd8"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145437"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn5AJq_7eGMc"
      },
      "source": [
        "data = data[:140000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igZ1m7fmCo1a"
      },
      "source": [
        "## Splitting our data into English and French sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izP_MfWeGMi"
      },
      "source": [
        "def build_english_french_sentences(data):\n",
        "    english_sentences = []\n",
        "    french_sentences = []\n",
        "    for data_point in data:\n",
        "        english_sentences.append(data_point.split(\"\\t\")[0])\n",
        "        french_sentences.append(data_point.split(\"\\t\")[1])\n",
        "    return english_sentences, french_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU1AA_dkeGMn"
      },
      "source": [
        "english_sentences, french_sentences = build_english_french_sentences(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHtX637EeGMs",
        "outputId": "b79463c4-a2d0-450f-e300-cba6554c259e"
      },
      "source": [
        "len(english_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwE2jPKIeGM1",
        "outputId": "86e44c8d-db5d-4d73-f1da-c1f93735fc1b"
      },
      "source": [
        "len(french_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egbo4BOECo1h"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizes characters\n",
        "Removes punctuation\n",
        "Performs case-folding\n",
        "Removes non-printable characters\n",
        "Keeps only alphabetic words"
      ],
      "metadata": {
        "id": "X2fbqv6ai3JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'My name is kalam..$@# :) assuming I am scientist!!!'\n",
        "cleaned_sent = normalize('NFD', sentence).encode('ascii', 'ignore')\n",
        "print(cleaned_sent)\n",
        "cleaned_sent = cleaned_sent.decode('UTF-8')\n",
        "print(cleaned_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjn1dCtUopwI",
        "outputId": "e6a6a60a-3789-46b7-83a1-c7353947a88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'My name is kalam..$@# :) assuming I am scientist!!!'\n",
            "My name is kalam..$@# :) assuming I am scientist!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgEQbWyLeGM6"
      },
      "source": [
        "def clean_sentences(sentence):\n",
        "    # prepare regex for char filtering\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    # prepare translation table for removing punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    #cleaned_sent = normalize('NFD', sentence).encode('ascii', 'ignore')\n",
        "    #cleaned_sent = cleaned_sent.decode('UTF-8')\n",
        "    #cleaned_sent = cleaned_sent.split()\n",
        "    cleaned_sent = sentence.split()\n",
        "    cleaned_sent = [word.lower() for word in cleaned_sent]\n",
        "    cleaned_sent = [word.translate(table) for word in cleaned_sent]\n",
        "    cleaned_sent = [re_print.sub('', w) for w in cleaned_sent]\n",
        "    cleaned_sent = [word for word in cleaned_sent if word.isalpha()]\n",
        "    return ' '.join(cleaned_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PEeqZNNeGM_"
      },
      "source": [
        "def build_clean_english_french_sentences(english_sentences, french_sentences):\n",
        "    french_sentences_cleaned = []\n",
        "    english_sentences_cleaned = []\n",
        "    for sent in french_sentences:\n",
        "        french_sentences_cleaned.append(clean_sentences(sent))\n",
        "    for sent in english_sentences:\n",
        "        english_sentences_cleaned.append(clean_sentences(sent))\n",
        "    return english_sentences_cleaned, french_sentences_cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpg30uqIeGND"
      },
      "source": [
        "english_sentences_cleaned, french_sentences_cleaned = build_clean_english_french_sentences(english_sentences,\n",
        "                                                                                           french_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KCJO0FNp4MZY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VPL2FfwweGNJ",
        "outputId": "8ac9836d-3bdf-46af-9c9c-f7e9e29a4397"
      },
      "source": [
        "english_sentences_cleaned[40884]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i think i can fix this'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2nokZ3D5eGNP",
        "outputId": "5102c971-33a6-40a2-e6e6-09d083090435"
      },
      "source": [
        "french_sentences_cleaned[40884]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'je pense que je peux arranger a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39F0x3owCo1m"
      },
      "source": [
        "## Building our input and target datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys2VR-NZeGNU"
      },
      "source": [
        "def build_data(english_sentences_cleaned, french_sentences_cleaned):\n",
        "    input_dataset = []\n",
        "    target_dataset = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "\n",
        "    for french_sentence in french_sentences_cleaned:\n",
        "        input_datapoint = french_sentence\n",
        "        input_dataset.append(input_datapoint)\n",
        "        for char in input_datapoint:\n",
        "            input_characters.add(char)\n",
        "\n",
        "    for english_sentence in english_sentences_cleaned:\n",
        "        target_datapoint = \"\\t\" + english_sentence + \"\\n\"\n",
        "        target_dataset.append(target_datapoint)\n",
        "        for char in target_datapoint:\n",
        "            target_characters.add(char)\n",
        "\n",
        "    return input_dataset, target_dataset, sorted(list(input_characters)), sorted(list(target_characters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrOsk6f_eGNb"
      },
      "source": [
        "input_dataset, target_dataset, input_characters, target_characters = build_data(english_sentences_cleaned,\n",
        "                                                                                french_sentences_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo7TiTaOeGNg",
        "outputId": "304dcf78-88bb-4d6c-c7de-cf44e9934ca6"
      },
      "source": [
        "len(input_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZqARjhWeGNl",
        "outputId": "81f0eaff-27fa-4f07-aaf3-0ca8046b21df"
      },
      "source": [
        "len(target_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ylMPx5neGNp",
        "outputId": "e898abf1-709b-47a8-eeed-70ea58854977"
      },
      "source": [
        "print(input_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CBV9vvieGNv",
        "outputId": "7a3b6d9d-1df9-4e4e-cd17-a963ed365d98"
      },
      "source": [
        "print(target_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\t', '\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjIxVrGqCo1t"
      },
      "source": [
        "## Defining metadata for our data structures and model to work with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Haj_b9-yeGNz"
      },
      "source": [
        "def build_metadata(input_dataset, target_dataset, input_characters, target_characters):\n",
        "    num_encoder_tokens = len(input_characters)\n",
        "    num_decoder_tokens = len(target_characters)\n",
        "    max_encoder_seq_length = max([len(data_point) for data_point in input_dataset])\n",
        "    max_decoder_seq_length = max([len(data_point) for data_point in target_dataset])\n",
        "\n",
        "    print('Number of data points:', len(input_dataset))\n",
        "    print('Number of unique input tokens:', num_encoder_tokens)\n",
        "    print('Number of unique output tokens:', num_decoder_tokens)\n",
        "    print('Maximum sequence length for inputs:', max_encoder_seq_length)\n",
        "    print('Maximum sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "    return num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To-bA7SPeGN3",
        "outputId": "c162fa35-1bf7-4e57-c2ac-f26a455996c9"
      },
      "source": [
        "num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length = build_metadata(input_dataset,\n",
        "                                                                                                        target_dataset,\n",
        "                                                                                                        input_characters,\n",
        "                                                                                                        target_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points: 140000\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 29\n",
            "Maximum sequence length for inputs: 109\n",
            "Maximum sequence length for outputs: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE4SqfvHCo1u"
      },
      "source": [
        "## Developing mappings for character to index and vice-versa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgmvQ088eGN7"
      },
      "source": [
        "def build_indices(input_characters, target_characters):\n",
        "    input_char_to_idx = {}\n",
        "    input_idx_to_char = {}\n",
        "    target_char_to_idx = {}\n",
        "    target_idx_to_char = {}\n",
        "\n",
        "    for i, char in enumerate(input_characters):\n",
        "        input_char_to_idx[char] = i\n",
        "        input_idx_to_char[i] = char\n",
        "\n",
        "    for i, char in enumerate(target_characters):\n",
        "        target_char_to_idx[char] = i\n",
        "        target_idx_to_char[i] = char\n",
        "\n",
        "    return input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char\n",
        "\n",
        "input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char = build_indices(input_characters,\n",
        "                                                                                             target_characters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnjk4s63Co1v"
      },
      "source": [
        "## Building data structures to accommodate our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwJ3acmneGN-",
        "outputId": "ff5aef12-742a-4c39-b76f-4ec33a44b39e"
      },
      "source": [
        "def build_data_structures(length_input_dataset, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens):\n",
        "    encoder_input_data = np.zeros((length_input_dataset, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "    decoder_input_data = np.zeros((length_input_dataset, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "    decoder_target_data = np.zeros((length_input_dataset, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "    print(\"Dimensionality of encoder input data is : \", encoder_input_data.shape)\n",
        "    print(\"Dimensionality of decoder input data is : \", decoder_input_data.shape)\n",
        "    print(\"Dimensionality of decoder target data is : \", decoder_target_data.shape)\n",
        "\n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
        "\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = build_data_structures(len(input_dataset),\n",
        "                                                                                    max_encoder_seq_length,\n",
        "                                                                                    max_decoder_seq_length,\n",
        "                                                                                    num_encoder_tokens,\n",
        "                                                                                    num_decoder_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensionality of encoder input data is :  (140000, 109, 27)\n",
            "Dimensionality of decoder input data is :  (140000, 58, 29)\n",
            "Dimensionality of decoder target data is :  (140000, 58, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iS_PsDZCo1w"
      },
      "source": [
        "## Adding data to the built data structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_okGtmkIeGOC"
      },
      "source": [
        "def add_data_to_data_structures(input_dataset, target_dataset, encoder_input_data, decoder_input_data, decoder_target_data):\n",
        "    for i, (input_data_point, target_data_point) in enumerate(zip(input_dataset, target_dataset)):\n",
        "        for t, char in enumerate(input_data_point):\n",
        "            encoder_input_data[i, t, input_char_to_idx[char]] = 1.\n",
        "        for t, char in enumerate(target_data_point):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            decoder_input_data[i, t, target_char_to_idx[char]] = 1.\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                decoder_target_data[i, t - 1, target_char_to_idx[char]] = 1.\n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQcJamwaeGOH"
      },
      "source": [
        "encoder_input_data, decoder_input_data, decoder_target_data = add_data_to_data_structures(input_dataset,\n",
        "                                                                                          target_dataset,\n",
        "                                                                                          encoder_input_data,\n",
        "                                                                                          decoder_input_data,\n",
        "                                                                                          decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXccj2ysCo1y"
      },
      "source": [
        "## Defining our model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwadHEJ1eGOM"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 100\n",
        "latent_dim = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW49hYIsCo1z"
      },
      "source": [
        "## Encoder Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think about how you would start an iteration of the LSTM. You have a hidden state c, an input x, but you also need an alleged previous output h, which is concatenated with x. The LSTM has therefore two hidden tensors that need to be initialized: c and h. Now h happens to be the output of the previous state, which is why you pass it as input together with c. When you set return_state=True, both c and h are returned. Together with the output, you'll therefore receive 3 tensors."
      ],
      "metadata": {
        "id": "I7eiVcKaFT3F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcXQZANneGOR"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKxnDp4TCo10"
      },
      "source": [
        "## Decoder Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return_sequence=TRUE, the output will be a sequence of the same length, with return_sequence=FALSE, the output will be just one vector."
      ],
      "metadata": {
        "id": "cprwPqZsDb1u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX_O_UzheGOX"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ittQn8oQCo10"
      },
      "source": [
        "## Building our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYIBY06AeGOb"
      },
      "source": [
        "model = Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "              outputs=decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG8R3LhFeGOf",
        "outputId": "217df6d8-1be1-40d8-f9c6-de68fb9ecff6"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 29)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        290816      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  292864      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 29)     7453        ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 591,133\n",
            "Trainable params: 591,133\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks9ERZ3CCo12"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cLKLtZLeGOk",
        "outputId": "e1af3839-4f77-44df-a4a7-c5610db39686"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "438/438 [==============================] - 55s 108ms/step - loss: 1.1711 - val_loss: 2.0792\n",
            "Epoch 2/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 1.0456 - val_loss: 1.9905\n",
            "Epoch 3/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.9851 - val_loss: 1.9009\n",
            "Epoch 4/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.9449 - val_loss: 1.8686\n",
            "Epoch 5/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.9153 - val_loss: 1.8059\n",
            "Epoch 6/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.8907 - val_loss: 1.6990\n",
            "Epoch 7/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.8715 - val_loss: 1.7151\n",
            "Epoch 8/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.8578 - val_loss: 1.7535\n",
            "Epoch 9/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.8467 - val_loss: 1.7169\n",
            "Epoch 10/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.8383 - val_loss: 1.6933\n",
            "Epoch 11/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.8309 - val_loss: 1.6451\n",
            "Epoch 12/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.8252 - val_loss: 1.6344\n",
            "Epoch 13/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.8200 - val_loss: 1.6095\n",
            "Epoch 14/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.8150 - val_loss: 1.6093\n",
            "Epoch 15/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.8107 - val_loss: 1.6561\n",
            "Epoch 16/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.8072 - val_loss: 1.6356\n",
            "Epoch 17/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.8034 - val_loss: 1.5875\n",
            "Epoch 18/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.8001 - val_loss: 1.5825\n",
            "Epoch 19/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7974 - val_loss: 1.5763\n",
            "Epoch 20/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7936 - val_loss: 1.5854\n",
            "Epoch 21/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7908 - val_loss: 1.5607\n",
            "Epoch 22/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7882 - val_loss: 1.5540\n",
            "Epoch 23/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7852 - val_loss: 1.5779\n",
            "Epoch 24/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7826 - val_loss: 1.5463\n",
            "Epoch 25/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7804 - val_loss: 1.5775\n",
            "Epoch 26/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7775 - val_loss: 1.5497\n",
            "Epoch 27/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.7747 - val_loss: 1.5598\n",
            "Epoch 28/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.7716 - val_loss: 1.5492\n",
            "Epoch 29/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7677 - val_loss: 1.5356\n",
            "Epoch 30/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7649 - val_loss: 1.5442\n",
            "Epoch 31/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7616 - val_loss: 1.5216\n",
            "Epoch 32/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.7594 - val_loss: 1.5007\n",
            "Epoch 33/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7543 - val_loss: 1.5026\n",
            "Epoch 34/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7508 - val_loss: 1.4936\n",
            "Epoch 35/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7470 - val_loss: 1.5038\n",
            "Epoch 36/100\n",
            "438/438 [==============================] - 45s 103ms/step - loss: 0.7447 - val_loss: 1.4761\n",
            "Epoch 37/100\n",
            "438/438 [==============================] - 45s 104ms/step - loss: 0.7407 - val_loss: 1.4741\n",
            "Epoch 38/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7386 - val_loss: 1.4596\n",
            "Epoch 39/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7363 - val_loss: 1.4818\n",
            "Epoch 40/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7359 - val_loss: 1.4635\n",
            "Epoch 41/100\n",
            "438/438 [==============================] - 46s 104ms/step - loss: 0.7336 - val_loss: 1.4630\n",
            "Epoch 42/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7311 - val_loss: 1.4920\n",
            "Epoch 43/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7259 - val_loss: 1.4432\n",
            "Epoch 44/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7230 - val_loss: 1.4390\n",
            "Epoch 45/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7202 - val_loss: 1.4378\n",
            "Epoch 46/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7180 - val_loss: 1.4285\n",
            "Epoch 47/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7152 - val_loss: 1.4315\n",
            "Epoch 48/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7125 - val_loss: 1.4242\n",
            "Epoch 49/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7110 - val_loss: 1.4370\n",
            "Epoch 50/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7086 - val_loss: 1.4230\n",
            "Epoch 51/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7067 - val_loss: 1.4254\n",
            "Epoch 52/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7056 - val_loss: 1.4101\n",
            "Epoch 53/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7040 - val_loss: 1.4181\n",
            "Epoch 54/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7034 - val_loss: 1.4024\n",
            "Epoch 55/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7030 - val_loss: 1.4153\n",
            "Epoch 56/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7021 - val_loss: 1.4156\n",
            "Epoch 57/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.7025 - val_loss: 1.3921\n",
            "Epoch 58/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6984 - val_loss: 1.3958\n",
            "Epoch 59/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6979 - val_loss: 1.4089\n",
            "Epoch 60/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6956 - val_loss: 1.3859\n",
            "Epoch 61/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6944 - val_loss: 1.3862\n",
            "Epoch 62/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6926 - val_loss: 1.3795\n",
            "Epoch 63/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6911 - val_loss: 1.3710\n",
            "Epoch 64/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6907 - val_loss: 1.4025\n",
            "Epoch 65/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6884 - val_loss: 1.3990\n",
            "Epoch 66/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6869 - val_loss: 1.3878\n",
            "Epoch 67/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6858 - val_loss: 1.3817\n",
            "Epoch 68/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6849 - val_loss: 1.3851\n",
            "Epoch 69/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6858 - val_loss: 1.3670\n",
            "Epoch 70/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6887 - val_loss: 1.3667\n",
            "Epoch 71/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6874 - val_loss: 1.3913\n",
            "Epoch 72/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6817 - val_loss: 1.3577\n",
            "Epoch 73/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6792 - val_loss: 1.4115\n",
            "Epoch 74/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6768 - val_loss: 1.3561\n",
            "Epoch 75/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6750 - val_loss: 1.3531\n",
            "Epoch 76/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6730 - val_loss: 1.3479\n",
            "Epoch 77/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6719 - val_loss: 1.3590\n",
            "Epoch 78/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6704 - val_loss: 1.3727\n",
            "Epoch 79/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6686 - val_loss: 1.3443\n",
            "Epoch 80/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6680 - val_loss: 1.3636\n",
            "Epoch 81/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6667 - val_loss: 1.3435\n",
            "Epoch 82/100\n",
            "438/438 [==============================] - 46s 105ms/step - loss: 0.6636 - val_loss: 1.3632\n",
            "Epoch 83/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6646 - val_loss: 1.3854\n",
            "Epoch 84/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6644 - val_loss: 1.3690\n",
            "Epoch 85/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6619 - val_loss: 1.3370\n",
            "Epoch 86/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6582 - val_loss: 1.3308\n",
            "Epoch 87/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6555 - val_loss: 1.3274\n",
            "Epoch 88/100\n",
            "438/438 [==============================] - 48s 109ms/step - loss: 0.6531 - val_loss: 1.3333\n",
            "Epoch 89/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6522 - val_loss: 1.3197\n",
            "Epoch 90/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6488 - val_loss: 1.3502\n",
            "Epoch 91/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6476 - val_loss: 1.3121\n",
            "Epoch 92/100\n",
            "438/438 [==============================] - 47s 106ms/step - loss: 0.6454 - val_loss: 1.3146\n",
            "Epoch 93/100\n",
            "438/438 [==============================] - 47s 106ms/step - loss: 0.6445 - val_loss: 1.3229\n",
            "Epoch 94/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6431 - val_loss: 1.3176\n",
            "Epoch 95/100\n",
            "438/438 [==============================] - 48s 109ms/step - loss: 0.6409 - val_loss: 1.3053\n",
            "Epoch 96/100\n",
            "438/438 [==============================] - 46s 106ms/step - loss: 0.6397 - val_loss: 1.3241\n",
            "Epoch 97/100\n",
            "438/438 [==============================] - 47s 106ms/step - loss: 0.6389 - val_loss: 1.3126\n",
            "Epoch 98/100\n",
            "438/438 [==============================] - 47s 106ms/step - loss: 0.6360 - val_loss: 1.3166\n",
            "Epoch 99/100\n",
            "438/438 [==============================] - 47s 106ms/step - loss: 0.6349 - val_loss: 1.3037\n",
            "Epoch 100/100\n",
            "438/438 [==============================] - 47s 106ms/step - loss: 0.6347 - val_loss: 1.2871\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e10086cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MxZL-JnCo13"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY80ZCIseGOo"
      },
      "source": [
        "model.save('/content/drive/MyDrive/2021_Courses/NLP/Practicals/Practical10/neural_machine_translation_french_to_english.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj5Ky3ODCo13"
      },
      "source": [
        "## Preparing our model for inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW9tivC9eGOt"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
        "                      [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9_DZBhyeGOx"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_char_to_idx['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_idx_to_char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "              stop_condition = True\n",
        "\n",
        "\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofg8ufJfCo15"
      },
      "source": [
        "## Let's translate some French sentences to English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7QnRlMHeGO1"
      },
      "source": [
        "def decode(seq_index):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_dataset[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IbAcQuDeGO5",
        "outputId": "c07e57d3-1166-4740-def7-1c9f2907c237"
      },
      "source": [
        "decode(55000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: hier etait une bonne journee\n",
            "Decoded sentence: stop still the store\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng_3YpbWXiZi",
        "outputId": "978c1238-2da3-4cd1-82bc-5d3c9de8d36b"
      },
      "source": [
        "decode(10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: jen ai ras le bol\n",
            "Decoded sentence: i was a lot to the the to the to the to the sere\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vh-z5N1ZOEM",
        "outputId": "286a9873-92fc-40cb-f542-db9d2a8d0fbd"
      },
      "source": [
        "decode(200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: soyez calmes\n",
            "Decoded sentence: a car is alle to the sere\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "P-VmNnYMZUMs",
        "outputId": "8bfc8543-cb20-4b22-8122-44c90c10f88a"
      },
      "source": [
        "decode(3000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: je me sens affreusement mal\n",
            "Decoded sentence: i feel like such an idiot\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "jo6-UTwnaEiU",
        "outputId": "19d48d04-f570-4d07-f153-1510bd1e16b9"
      },
      "source": [
        "decode(40884)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: je pense que je peux arranger ca\n",
            "Decoded sentence: i think i can do it\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahYsw5CESe6a"
      },
      "source": [
        "OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLecOpzat1oi",
        "outputId": "8d5f74b1-fee8-49b8-d651-e16bef93309b"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "586cue8itnDB",
        "outputId": "0a84a3ac-82b6-49e2-fd97-ebc06f2d8678"
      },
      "source": [
        "!pip install pytesseract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.9)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (9.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "tTsVVajPtj8Z",
        "outputId": "02533ab1-eb68-49b6-f7cc-0766001aeb81"
      },
      "source": [
        "# !sudo apt install tesseract-ocr\n",
        "# !pip install pytesseract\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "extractedInformation = pytesseract.image_to_string(Image.open('/content/for_OCR.jpg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1c273b8e-44e7-47df-aefa-649af76fd8cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1c273b8e-44e7-47df-aefa-649af76fd8cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 251b49d12a07851ffde9912af40b4513.jpg to 251b49d12a07851ffde9912af40b4513 (2).jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-241642519414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mextractedInformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/for_OCR.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2852\u001b[0m         \u001b[0mfull\u001b[0m \u001b[0mset\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2854\u001b[0;31m             \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2856\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpreinit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mJpegImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTiffImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi16be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi32be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRational\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTiffTags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi16be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi32be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcontain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \"\"\"\n\u001b[1;32m    242\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mresized\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         warnings.warn(\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;34m\"Image categories are \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdeprecated\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Use is_animated instead.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'Resampling'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1xE8l5fcuZIQ",
        "outputId": "b1b7fc0e-f4a5-4821-9b1b-7e5fb0be0cee"
      },
      "source": [
        "extractedInformation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"L'Inde a remporte le\\nmatch\\n\\x0c\""
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow==9.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "UyDhWeZgZRvK",
        "outputId": "d648c05d-8646-4d86-a301-1862cf1ac3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==9.0.0\n",
            "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.1.0\n",
            "    Uninstalling Pillow-9.1.0:\n",
            "      Successfully uninstalled Pillow-9.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWtMMIRWuuKT",
        "outputId": "097c70f6-4c11-40b6-cf2c-49c53d083a54"
      },
      "source": [
        "import cv2\n",
        "from pytesseract import image_to_string\n",
        "img_cv = cv2.imread(r'/content/demo.jpg')\n",
        "print(image_to_string(img_cv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Je ne sais pas\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgsv0R2Ix2RL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}